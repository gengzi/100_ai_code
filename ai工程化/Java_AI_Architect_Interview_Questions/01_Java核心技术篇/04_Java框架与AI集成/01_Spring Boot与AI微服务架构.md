# Spring Bootä¸AIå¾®æœåŠ¡æ¶æ„ (100é¢˜)

## â­ åŸºç¡€é¢˜ (1-30)

### é—®é¢˜1: è®¾è®¡åŸºäºSpring Bootçš„AIæ¨ç†å¾®æœåŠ¡æ¶æ„

**é¢è¯•é¢˜**: å¦‚ä½•ä½¿ç”¨Spring Bootè®¾è®¡é«˜å¯ç”¨çš„AIæ¨ç†å¾®æœåŠ¡ï¼Ÿ

**å£è¯­åŒ–ç­”æ¡ˆ**:
"æˆ‘ä¼šè®¾è®¡ä¸€ä¸ªåˆ†å±‚çš„Spring Boot AIå¾®æœåŠ¡æ¶æ„ï¼ŒåŒ…å«æœåŠ¡æ³¨å†Œã€è´Ÿè½½å‡è¡¡ã€ç†”æ–­å™¨ç­‰ç»„ä»¶ï¼š

```java
// ä¸»åº”ç”¨å…¥å£
@SpringBootApplication
@EnableEurekaClient
@EnableCircuitBreaker
@EnableDiscoveryClient
public class AIInferenceApplication {
    public static void main(String[] args) {
        SpringApplication.run(AIInferenceApplication.class, args);
    }

    @Bean
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }

    @Bean
    public TaskExecutor inferenceTaskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(8);
        executor.setMaxPoolSize(16);
        executor.setQueueCapacity(100);
        executor.setThreadNamePrefix("ai-inference-");
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.initialize();
        return executor;
    }
}

// AIæ¨ç†æœåŠ¡
@RestController
@RequestMapping("/api/v1/inference")
@Slf4j
public class InferenceController {

    private final AIInferenceService inferenceService;
    private final ModelService modelService;
    private final MetricsCollector metrics;

    public InferenceController(AIInferenceService inferenceService,
                              ModelService modelService,
                              MetricsCollector metrics) {
        this.inferenceService = inferenceService;
        this.modelService = modelService;
        this.metrics = metrics;
    }

    @PostMapping("/predict")
    @Timed(name = "inference.predict", description = "Time taken to perform prediction")
    public CompletableFuture<ResponseEntity<InferenceResponse>> predict(
            @RequestBody @Valid InferenceRequest request,
            @RequestHeader("X-Model-Version") String modelVersion) {

        long startTime = System.currentTimeMillis();

        return CompletableFuture.supplyAsync(() -> {
            try {
                // æ¨¡å‹ç‰ˆæœ¬æ£€æŸ¥
                ModelMetadata model = modelService.getModel(request.getModelId(), modelVersion);
                if (model == null) {
                    throw new ModelNotFoundException("æ¨¡å‹æœªæ‰¾åˆ°: " + request.getModelId());
                }

                // æ‰§è¡Œæ¨ç†
                InferenceResult result = inferenceService.predict(request, model);

                // è®°å½•æŒ‡æ ‡
                long duration = System.currentTimeMillis() - startTime;
                metrics.recordInference(request.getModelId(), duration, result.getConfidence());

                return ResponseEntity.ok(new InferenceResponse(
                    result.getPrediction(),
                    result.getConfidence(),
                    result.getProcessingTime(),
                    model.getVersion()
                ));

            } catch (Exception e) {
                log.error("æ¨ç†å¤±è´¥", e);
                throw new InferenceException("æ¨ç†å¤„ç†å¤±è´¥: " + e.getMessage());
            }
        }, inferenceTaskExecutor());
    }

    @PostMapping("/batch")
    public ResponseEntity<List<InferenceResponse>> batchPredict(
            @RequestBody @Valid BatchInferenceRequest request) {

        if (request.getRequests().size() > 100) {
            throw new InvalidBatchSizeException("æ‰¹æ¬¡å¤§å°ä¸èƒ½è¶…è¿‡100");
        }

        List<CompletableFuture<InferenceResponse>> futures = request.getRequests().stream()
            .map(req -> predict(req, "latest"))
            .map(future -> future.thenApply(ResponseEntity::getBody))
            .collect(Collectors.toList());

        try {
            List<InferenceResponse> results = futures.stream()
                .map(CompletableFuture::join)
                .collect(Collectors.toList());

            return ResponseEntity.ok(results);
        } catch (Exception e) {
            log.error("æ‰¹é‡æ¨ç†å¤±è´¥", e);
            throw new InferenceException("æ‰¹é‡æ¨ç†å¤±è´¥: " + e.getMessage());
        }
    }

    @GetMapping("/models")
    public ResponseEntity<List<ModelInfo>> getAvailableModels() {
        List<ModelInfo> models = modelService.getAvailableModels();
        return ResponseEntity.ok(models);
    }

    @GetMapping("/health")
    public ResponseEntity<HealthStatus> healthCheck() {
        return ResponseEntity.ok(new HealthStatus(
            inferenceService.isHealthy(),
            modelService.isHealthy(),
            System.currentTimeMillis()
        ));
    }
}

// AIæ¨ç†æœåŠ¡æ¥å£å’Œå®ç°
@Service
@Slf4j
public class AIInferenceService {

    private final ModelCache modelCache;
    private final InferenceEngine inferenceEngine;
    private final AsyncInferenceQueue inferenceQueue;

    public AIInferenceService(ModelCache modelCache,
                              InferenceEngine inferenceEngine,
                              AsyncInferenceQueue inferenceQueue) {
        this.modelCache = modelCache;
        this.inferenceEngine = inferenceEngine;
        this.inferenceQueue = inferenceQueue;
    }

    @HystrixCommand(
        fallbackMethod = "fallbackPredict",
        commandProperties = {
            @HystrixProperty(name = "execution.isolation.thread.timeoutInMilliseconds", value = "5000"),
            @HystrixProperty(name = "circuitBreaker.requestVolumeThreshold", value = "20"),
            @HystrixProperty(name = "circuitBreaker.sleepWindowInMilliseconds", value = "10000"),
            @HystrixProperty(name = "circuitBreaker.errorThresholdPercentage", value = "50")
        }
    )
    public InferenceResult predict(InferenceRequest request, ModelMetadata model) {
        try {
            // è·å–æˆ–åŠ è½½æ¨¡å‹
            AIModel aiModel = modelCache.getOrLoad(model);

            // æ•°æ®é¢„å¤„ç†
            PreprocessedData preprocessedData = preprocessInput(request.getInput());

            // æ‰§è¡Œæ¨ç†
            Object prediction = inferenceEngine.infer(aiModel, preprocessedData);

            // åå¤„ç†
            InferenceResult result = postprocessResult(prediction);

            log.info("æ¨ç†å®Œæˆ: æ¨¡å‹={}, è€—æ—¶={}ms", model.getModelId(), result.getProcessingTime());
            return result;

        } catch (Exception e) {
            log.error("æ¨ç†æ‰§è¡Œå¤±è´¥: æ¨¡å‹={}", model.getModelId(), e);
            throw new InferenceException("æ¨ç†æ‰§è¡Œå¤±è´¥", e);
        }
    }

    public InferenceResult fallbackPredict(InferenceRequest request, ModelMetadata model, Throwable t) {
        log.warn("æ¨ç†æœåŠ¡é™çº§ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: æ¨¡å‹={}, åŸå› ={}", model.getModelId(), t.getMessage());

        try {
            // ä½¿ç”¨é»˜è®¤è½»é‡çº§æ¨¡å‹
            ModelMetadata defaultModel = modelService.getDefaultModel();
            return predict(request, defaultModel);
        } catch (Exception e) {
            log.error("é™çº§æ¨ç†ä¹Ÿå¤±è´¥", e);
            return new InferenceResult("é™çº§å¤±è´¥", 0.0, 0);
        }
    }

    private PreprocessedData preprocessInput(Object input) {
        // å®ç°æ•°æ®é¢„å¤„ç†é€»è¾‘
        return new PreprocessedData(input);
    }

    private InferenceResult postprocessResult(Object prediction) {
        // å®ç°ç»“æœåå¤„ç†é€»è¾‘
        return new InferenceResult(prediction.toString(), 0.95, 100);
    }

    public boolean isHealthy() {
        return inferenceEngine.isHealthy() && modelCache.isHealthy();
    }
}

// æ¨¡å‹æœåŠ¡
@Service
@Slf4j
public class ModelService {

    private final ModelRepository modelRepository;
    private final ModelLoader modelLoader;
    private final ModelRegistry modelRegistry;

    @Cacheable(value = "models", key = "#modelId + ':' + #version")
    public ModelMetadata getModel(String modelId, String version) {
        log.info("è·å–æ¨¡å‹å…ƒæ•°æ®: modelId={}, version={}", modelId, version);

        return modelRepository.findByModelIdAndVersion(modelId, version)
            .orElseThrow(() -> new ModelNotFoundException("æ¨¡å‹æœªæ‰¾åˆ°: " + modelId));
    }

    @CacheEvict(value = "models", key = "#modelId + ':' + #version")
    public void evictModelCache(String modelId, String version) {
        log.info("æ¸…é™¤æ¨¡å‹ç¼“å­˜: modelId={}, version={}", modelId, version);
    }

    public List<ModelInfo> getAvailableModels() {
        return modelRepository.findAll().stream()
            .filter(ModelMetadata::isActive)
            .map(this::convertToModelInfo)
            .collect(Collectors.toList());
    }

    public ModelMetadata getDefaultModel() {
        return modelRepository.findByIsDefaultTrue()
            .orElseThrow(() -> new ModelNotFoundException("é»˜è®¤æ¨¡å‹æœªé…ç½®"));
    }

    public boolean isHealthy() {
        try {
            // æ£€æŸ¥æ¨¡å‹æ•°æ®åº“è¿æ¥
            modelRepository.count();
            return true;
        } catch (Exception e) {
            log.error("æ¨¡å‹æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥", e);
            return false;
        }
    }

    private ModelInfo convertToModelInfo(ModelMetadata metadata) {
        return new ModelInfo(
            metadata.getModelId(),
            metadata.getName(),
            metadata.getVersion(),
            metadata.getDescription(),
            metadata.getModelType(),
            metadata.getCreatedAt()
        );
    }
}

// æ¨¡å‹ç¼“å­˜ç®¡ç†
@Component
@Slf4j
public class ModelCache {

    private final Cache<String, AIModel> modelCache;
    private final ModelLoader modelLoader;
    private final MetricsCollector metrics;

    public ModelCache(ModelLoader modelLoader, MetricsCollector metrics) {
        this.modelLoader = modelLoader;
        this.metrics = metrics;
        this.modelCache = Caffeine.newBuilder()
            .maximumSize(10)
            .expireAfterAccess(30, TimeUnit.MINUTES)
            .recordStats()
            .removalListener((key, value, cause) -> {
                log.info("æ¨¡å‹è¢«ç§»å‡ºç¼“å­˜: key={}, cause={}", key, cause);
                metrics.recordModelEviction(cause.name());
            })
            .build();
    }

    public AIModel getOrLoad(ModelMetadata metadata) {
        String cacheKey = metadata.getModelId() + ":" + metadata.getVersion();

        return modelCache.get(cacheKey, key -> {
            log.info("åŠ è½½æ¨¡å‹åˆ°ç¼“å­˜: {}", key);
            long startTime = System.currentTimeMillis();

            try {
                AIModel model = modelLoader.loadModel(metadata);
                long loadTime = System.currentTimeMillis() - startTime;
                metrics.recordModelLoad(metadata.getModelId(), loadTime);
                return model;
            } catch (Exception e) {
                log.error("æ¨¡å‹åŠ è½½å¤±è´¥: {}", key, e);
                throw new ModelLoadException("æ¨¡å‹åŠ è½½å¤±è´¥: " + key, e);
            }
        });
    }

    public void preloadModels(List<ModelMetadata> models) {
        log.info("é¢„åŠ è½½æ¨¡å‹: {}", models.size());
        models.parallelStream().forEach(this::getOrLoad);
    }

    public void clear() {
        modelCache.invalidateAll();
    }

    public CacheStats getStats() {
        return modelCache.stats();
    }

    public boolean isHealthy() {
        return getStats().missRate() < 0.1; // ç¼“å­˜æœªå‘½ä¸­ç‡ä½äº10%
    }
}

// å¼‚æ­¥æ¨ç†é˜Ÿåˆ—
@Component
@Slf4j
public class AsyncInferenceQueue {

    private final DisruptorQueue<InferenceTask> taskQueue;
    private final ExecutorService processorPool;

    public AsyncInferenceQueue(@Value("${ai.inference.queue.size:1000}") int queueSize,
                              @Value("${ai.inference.processors:8}") int processors) {
        this.taskQueue = new DisruptorQueue<>(queueSize);
        this.processorPool = Executors.newFixedThreadPool(processors,
            r -> new Thread(r, "inference-processor-"));

        startProcessors();
    }

    private void startProcessors() {
        for (int i = 0; i < processorPool.getThreadPoolExecutor().getCorePoolSize(); i++) {
            processorPool.submit(this::processLoop);
        }
    }

    private void processLoop() {
        while (!Thread.currentThread().isInterrupted()) {
            try {
                InferenceTask task = taskQueue.take(1, TimeUnit.SECONDS);
                if (task != null) {
                    processTask(task);
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                break;
            } catch (Exception e) {
                log.error("æ¨ç†ä»»åŠ¡å¤„ç†å¤±è´¥", e);
            }
        }
    }

    public CompletableFuture<InferenceResult> submit(InferenceRequest request, ModelMetadata model) {
        CompletableFuture<InferenceResult> future = new CompletableFuture<>();
        InferenceTask task = new InferenceTask(request, model, future);

        if (!taskQueue.offer(task)) {
            future.completeExceptionally(new QueueFullException("æ¨ç†é˜Ÿåˆ—å·²æ»¡"));
        }

        return future;
    }

    private void processTask(InferenceTask task) {
        try {
            // æ‰§è¡Œæ¨ç†ä»»åŠ¡
            InferenceResult result = executeInference(task.getRequest(), task.getModel());
            task.getFuture().complete(result);
        } catch (Exception e) {
            log.error("æ¨ç†ä»»åŠ¡æ‰§è¡Œå¤±è´¥", e);
            task.getFuture().completeExceptionally(e);
        }
    }

    private InferenceResult executeInference(InferenceRequest request, ModelMetadata model) {
        // å®é™…æ¨ç†æ‰§è¡Œé€»è¾‘
        return new InferenceResult("async_result", 0.92, 80);
    }
}

// é…ç½®ç±»
@Configuration
@EnableConfigurationProperties({AIProperties.class, CacheProperties.class})
public class AIConfiguration {

    @Bean
    @ConditionalOnMissingBean
    public ModelRepository modelRepository(ModelProperties modelProperties) {
        // æ ¹æ®é…ç½®åˆ›å»ºä¸åŒçš„å­˜å‚¨å®ç°
        if (modelProperties.getStorage().equals("database")) {
            return new DatabaseModelRepository();
        } else if (modelProperties.getStorage().equals("file")) {
            return new FileModelRepository();
        } else {
            return new InMemoryModelRepository();
        }
    }

    @Bean
    public MetricsCollector metricsCollector() {
        return new MetricsCollector();
    }

    @Bean
    public CustomHealthIndicator customHealthIndicator(
            AIInferenceService inferenceService,
            ModelService modelService) {
        return new CustomHealthIndicator(inferenceService, modelService);
    }
}

// é…ç½®å±æ€§
@ConfigurationProperties(prefix = "ai")
@Data
public class AIProperties {
    private String modelPath = "/models";
    private int maxConcurrentInferences = 100;
    private long inferenceTimeout = 5000;
    private boolean enableCaching = true;
    private ModelProperties model = new ModelProperties();

    @Data
    public static class ModelProperties {
        private String storage = "database";
        private String defaultModel = "default";
        private int maxCacheSize = 10;
    }
}

@ConfigurationProperties(prefix = "cache")
@Data
public class CacheProperties {
    private int maxSize = 100;
    private Duration expireAfterAccess = Duration.ofMinutes(30);
    private Duration expireAfterWrite = Duration.ofHours(2);
}

// å¥åº·æ£€æŸ¥
@Component
public class CustomHealthIndicator implements HealthIndicator {

    private final AIInferenceService inferenceService;
    private final ModelService modelService;

    public CustomHealthIndicator(AIInferenceService inferenceService, ModelService modelService) {
        this.inferenceService = inferenceService;
        this.modelService = modelService;
    }

    @Override
    public Health health() {
        boolean inferenceHealthy = inferenceService.isHealthy();
        boolean modelHealthy = modelService.isHealthy();

        Health.Builder builder = inferenceHealthy && modelHealthy ?
            Health.up() : Health.down();

        return builder
            .withDetail("inference", inferenceHealthy ? "UP" : "DOWN")
            .withDetail("models", modelHealthy ? "UP" : "DOWN")
            .withDetail("timestamp", System.currentTimeMillis())
            .build();
    }
}
```

## â­â­ è¿›é˜¶é¢˜ (31-70)

### é—®é¢˜31: Spring Cloudåœ¨AIå¾®æœåŠ¡æ²»ç†ä¸­çš„åº”ç”¨

**é¢è¯•é¢˜**: å¦‚ä½•ä½¿ç”¨Spring Cloudå®ç°AIå¾®æœåŠ¡çš„æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡å’Œç†”æ–­ä¿æŠ¤ï¼Ÿ

**å£è¯­åŒ–ç­”æ¡ˆ**:
"Spring Cloudæä¾›äº†å®Œæ•´çš„å¾®æœåŠ¡æ²»ç†ç”Ÿæ€ã€‚æˆ‘ä¼šè¿™æ ·è®¾è®¡AIå¾®æœåŠ¡æ²»ç†ï¼š

```java
// é…ç½®æœåŠ¡å™¨
@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConfigServerApplication.class, args);
    }
}

// æœåŠ¡æ³¨å†Œä¸­å¿ƒ
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaServerApplication.class, args);
    }
}

// APIç½‘å…³
@SpringBootApplication
@EnableZuulProxy
@EnableCircuitBreaker
public class APIGatewayApplication {

    @Bean
    public PreFilter preFilter() {
        return new APIKeyFilter();
    }

    @Bean
    public PostFilter postFilter() {
        return new ResponseTimeFilter();
    }
}

// APIå¯†é’¥è¿‡æ»¤å™¨
public class APIKeyFilter extends ZuulFilter {

    @Override
    public String filterType() {
        return "pre";
    }

    @Override
    public int filterOrder() {
        return 1;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    @Override
    public Object run() throws ZuulException {
        RequestContext ctx = RequestContext.getCurrentContext();
        HttpServletRequest request = ctx.getRequest();

        String apiKey = request.getHeader("X-API-Key");
        if (!isValidApiKey(apiKey)) {
            ctx.setSendZuulResponse(false);
            ctx.setResponseStatusCode(401);
            ctx.setResponseBody("{\"error\":\"Invalid API Key\"}");
        }

        return null;
    }

    private boolean isValidApiKey(String apiKey) {
        // å®ç°APIå¯†é’¥éªŒè¯é€»è¾‘
        return apiKey != null && apiKey.startsWith("ai-");
    }
}

// AIæœåŠ¡å‘ç°å®¢æˆ·ç«¯
@Component
@Slf4j
public class AIServiceDiscovery {

    private final DiscoveryClient discoveryClient;
    private final LoadBalancerClient loadBalancerClient;
    private final RestTemplate restTemplate;

    public AIServiceDiscovery(DiscoveryClient discoveryClient,
                              LoadBalancerClient loadBalancerClient,
                              RestTemplate restTemplate) {
        this.discoveryClient = discoveryClient;
        this.loadBalancerClient = loadBalancerClient;
        this.restTemplate = restTemplate;
    }

    public List<ServiceInstance> getInferenceServices() {
        return discoveryClient.getInstances("ai-inference-service");
    }

    public ServiceInstance getBestInferenceService() {
        return loadBalancerClient.choose("ai-inference-service");
    }

    @HystrixCommand(
        fallbackMethod = "fallbackInference",
        commandProperties = {
            @HystrixProperty(name = "execution.isolation.thread.timeoutInMilliseconds", value = "3000")
        }
    )
    public InferenceResult callInferenceService(InferenceRequest request) {
        ServiceInstance instance = getBestInferenceService();
        if (instance == null) {
            throw new ServiceUnavailableException("æ²¡æœ‰å¯ç”¨çš„AIæ¨ç†æœåŠ¡");
        }

        String url = "http://" + instance.getHost() + ":" + instance.getPort() + "/api/v1/inference/predict";

        try {
            ResponseEntity<InferenceResponse> response = restTemplate.postForEntity(url, request, InferenceResponse.class);
            return convertToResult(response.getBody());
        } catch (Exception e) {
            log.error("è°ƒç”¨AIæ¨ç†æœåŠ¡å¤±è´¥", e);
            throw new ServiceCallException("AIæ¨ç†æœåŠ¡è°ƒç”¨å¤±è´¥", e);
        }
    }

    public InferenceResult fallbackInference(InferenceRequest request, Throwable t) {
        log.warn("AIæ¨ç†æœåŠ¡é™çº§ï¼Œä½¿ç”¨ç¼“å­˜æˆ–é»˜è®¤ç»“æœ");
        return new InferenceResult("é™çº§ç»“æœ", 0.8, 0);
    }

    private InferenceResult convertToResult(InferenceResponse response) {
        return new InferenceResult(
            response.getPrediction(),
            response.getConfidence(),
            response.getProcessingTime()
        );
    }

    // å¥åº·æ£€æŸ¥æ‰€æœ‰AIæœåŠ¡å®ä¾‹
    public Map<String, Boolean> healthCheckAllServices() {
        Map<String, Boolean> healthStatus = new HashMap<>();

        List<ServiceInstance> instances = getInferenceServices();
        for (ServiceInstance instance : instances) {
            String healthUrl = "http://" + instance.getHost() + ":" + instance.getPort() + "/health";
            try {
                ResponseEntity<HealthStatus> response = restTemplate.getForEntity(healthUrl, HealthStatus.class);
                healthStatus.put(instance.getInstanceId(), response.getStatusCode().is2xxSuccessful());
            } catch (Exception e) {
                healthStatus.put(instance.getInstanceId(), false);
            }
        }

        return healthStatus;
    }
}

// è´Ÿè½½å‡è¡¡ç­–ç•¥é…ç½®
@Configuration
public class LoadBalancerConfiguration {

    @Bean
    public IRule aiServiceRule() {
        // åŸºäºå“åº”æ—¶é—´çš„è´Ÿè½½å‡è¡¡ç­–ç•¥
        return new WeightedResponseTimeRule();
    }

    @Bean
    public IPing aiServicePing() {
        // è‡ªå®šä¹‰å¥åº·æ£€æŸ¥
        return new AIPing();
    }

    private static class AIPing implements IPing {
        private final RestTemplate restTemplate = new RestTemplate();

        @Override
        public boolean isAlive(Server server) {
            try {
                String url = "http://" + server.getHost() + ":" + server.getPort() + "/health";
                ResponseEntity<String> response = restTemplate.getForEntity(url, String.class);
                return response.getStatusCode().is2xxSuccessful();
            } catch (Exception e) {
                return false;
            }
        }
    }
}

// é…ç½®ç®¡ç†
@RestController
@RefreshScope
@RequestMapping("/api/v1/config")
public class ConfigurationController {

    @Value("${ai.inference.timeout:5000}")
    private long inferenceTimeout;

    @Value("${ai.inference.retries:3}")
    private int maxRetries;

    @Value("${ai.models.default:default}")
    private String defaultModel;

    @GetMapping("/inference")
    public InferenceConfig getInferenceConfig() {
        return new InferenceConfig(inferenceTimeout, maxRetries);
    }

    @PostMapping("/inference")
    public ResponseEntity<String> updateInferenceConfig(@RequestBody InferenceConfig config) {
        // æ›´æ–°é…ç½®çš„é€»è¾‘
        return ResponseEntity.ok("é…ç½®æ›´æ–°æˆåŠŸ");
    }

    @GetMapping("/models/default")
    public String getDefaultModel() {
        return defaultModel;
    }
}

// é“¾è·¯è¿½è¸ª
@Component
@Slf4j
public class AITracingInterceptor implements HandlerInterceptor {

    private final Tracer tracer;

    public AITracingInterceptor(Tracer tracer) {
        this.tracer = tracer;
    }

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) {
        Span span = tracer.nextSpan().name("ai-inference");
        span.tag("service.name", "ai-inference");
        span.tag("http.method", request.getMethod());
        span.tag("http.url", request.getRequestURI());

        span.start();
        tracer.withSpan(span);

        // å°†traceä¿¡æ¯æ·»åŠ åˆ°å“åº”å¤´
        response.addHeader("X-Trace-Id", span.context().traceId());
        response.addHeader("X-Span-Id", span.context().spanId());

        return true;
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response,
                               Object handler, Exception ex) {
        Span span = tracer.currentSpan();
        if (span != null) {
            if (ex != null) {
                span.tag("error", ex.getMessage());
            }
            span.end();
        }
    }
}

// æŒ‡æ ‡æ”¶é›†
@Component
@Slf4j
public class AIMetricsCollector {

    private final MeterRegistry meterRegistry;
    private final Counter inferenceRequests;
    private final Timer inferenceTimer;
    private final Gauge activeInferences;

    private final AtomicInteger activeInferenceCount = new AtomicInteger(0);

    public AIMetricsCollector(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.inferenceRequests = Counter.builder("ai.inference.requests")
            .description("AIæ¨ç†è¯·æ±‚æ•°é‡")
            .register(meterRegistry);

        this.inferenceTimer = Timer.builder("ai.inference.duration")
            .description("AIæ¨ç†è€—æ—¶")
            .register(meterRegistry);

        this.activeInferences = Gauge.builder("ai.inference.active")
            .description("æ´»è·ƒæ¨ç†æ•°é‡")
            .register(meterRegistry, activeInferenceCount, AtomicInteger::get);
    }

    public void recordInferenceStart() {
        activeInferenceCount.incrementAndGet();
        inferenceRequests.increment();
    }

    public void recordInferenceEnd(long durationMs) {
        activeInferenceCount.decrementAndGet();
        inferenceTimer.record(durationMs, TimeUnit.MILLISECONDS);
    }

    public void recordModelLoad(String modelId, long loadTimeMs) {
        Timer.Sample sample = Timer.start(meterRegistry);
        sample.stop(Timer.builder("ai.model.load.duration")
            .tag("model.id", modelId)
            .register(meterRegistry));
    }

    public void recordModelEviction(String cause) {
        Counter.builder("ai.model.evictions")
            .tag("cause", cause)
            .register(meterRegistry)
            .increment();
    }
}
```

## â­â­â­ ä¸“å®¶é¢˜ (71-100)

### é—®é¢˜71: åŸºäºSpring Cloud Streamçš„å®æ—¶AIäº‹ä»¶å¤„ç†æ¶æ„

**é¢è¯•é¢˜**: å¦‚ä½•è®¾è®¡åŸºäºSpring Cloud Streamçš„å®æ—¶AIäº‹ä»¶å¤„ç†ç³»ç»Ÿï¼Œæ”¯æŒæµå¼æ¨ç†å’Œäº‹ä»¶æº¯æºï¼Ÿ

**å£è¯­åŒ–ç­”æ¡ˆ**:
"æˆ‘ä¼šè®¾è®¡ä¸€ä¸ªåŸºäºäº‹ä»¶é©±åŠ¨çš„å®æ—¶AIå¤„ç†æ¶æ„ï¼Œæ”¯æŒæµå¼æ¨ç†å’Œäº‹ä»¶æº¯æºï¼š

```java
// äº‹ä»¶é©±åŠ¨çš„AIå¤„ç†åº”ç”¨
@SpringBootApplication
@EnableBinding(AIProcessingChannels.class)
public class AIEventProcessingApplication {

    public static void main(String[] args) {
        SpringApplication.run(AIEventProcessingApplication.class, args);
    }

    @Bean
    public AIEventProcessor eventProcessor() {
        return new AIEventProcessor();
    }

    @Bean
    public StreamListener streamListener() {
        return new StreamListener();
    }
}

// AIå¤„ç†é€šé“å®šä¹‰
public interface AIProcessingChannels {

    String INFERENCE_INPUT = "ai.inference.input";
    String INFERENCE_OUTPUT = "ai.inference.output";
    String MODEL_EVENTS = "ai.model.events";
    String METRICS = "ai.metrics";
    String DEAD_LETTER = "ai.deadletter";

    @Input(INFERENCE_INPUT)
    SubscribableChannel inferenceInput();

    @Output(INFERENCE_OUTPUT)
    MessageChannel inferenceOutput();

    @Input(MODEL_EVENTS)
    SubscribableChannel modelEvents();

    @Output(MODEL_EVENTS)
    MessageChannel modelEventOutput();

    @Input(METRICS)
    SubscribableChannel metrics();

    @Output(METRICS)
    MessageChannel metricsOutput();

    @Input(DEAD_LETTER)
    SubscribableChannel deadLetter();

    @Output(DEAD_LETTER)
    MessageChannel deadLetterOutput();
}

// AIäº‹ä»¶å¤„ç†å™¨
@Component
@Slf4j
public class AIEventProcessor {

    private final StreamInferenceService inferenceService;
    private final ModelEventStore modelEventStore;
    private final EventSourcingService eventSourcingService;
    private final MetricsCollector metricsCollector;

    public AIEventProcessor(StreamInferenceService inferenceService,
                           ModelEventStore modelEventStore,
                           EventSourcingService eventSourcingService,
                           MetricsCollector metricsCollector) {
        this.inferenceService = inferenceService;
        this.modelEventStore = modelEventStore;
        this.eventSourcingService = eventSourcingService;
        this.metricsCollector = metricsCollector;
    }

    @StreamListener(target = AIProcessingChannels.INFERENCE_INPUT)
    public void handleInferenceRequest(Message<InferenceEvent> message) {
        try {
            InferenceEvent event = message.getPayload();
            log.info("å¤„ç†æ¨ç†äº‹ä»¶: eventId={}, modelId={}", event.getEventId(), event.getModelId());

            // äº‹ä»¶æº¯æºï¼šå­˜å‚¨æ¨ç†äº‹ä»¶
            eventSourcingService.saveEvent(event);

            // è·å–å½“å‰æ¨¡å‹çŠ¶æ€
            ModelState currentModelState = modelEventStore.getCurrentModelState(event.getModelId());
            if (currentModelState == null) {
                throw new ModelStateException("æ¨¡å‹çŠ¶æ€æœªæ‰¾åˆ°: " + event.getModelId());
            }

            // æ‰§è¡Œæµå¼æ¨ç†
            CompletableFuture<InferenceResult> resultFuture = inferenceService.streamInference(
                event.getInputData(), currentModelState);

            // å¤„ç†æ¨ç†ç»“æœ
            resultFuture.thenAccept(result -> {
                // å‘å¸ƒæ¨ç†å®Œæˆäº‹ä»¶
                publishInferenceCompletedEvent(event, result);

                // å‘é€æŒ‡æ ‡äº‹ä»¶
                publishMetricsEvent(event, result);

            }).exceptionally(throwable -> {
                // å¤„ç†æ¨ç†å¤±è´¥
                log.error("æ¨ç†å¤±è´¥: eventId={}", event.getEventId(), throwable);
                publishInferenceFailedEvent(event, throwable);
                return null;
            });

        } catch (Exception e) {
            log.error("å¤„ç†æ¨ç†äº‹ä»¶å¤±è´¥", e);
            // å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
            sendToDeadLetter(message, e);
        }
    }

    @StreamListener(target = AIProcessingChannels.MODEL_EVENTS)
    public void handleModelEvent(Message<ModelEvent> message) {
        ModelEvent event = message.getPayload();
        log.info("å¤„ç†æ¨¡å‹äº‹ä»¶: eventId={}, eventType={}", event.getEventId(), event.getEventType());

        try {
            // äº‹ä»¶æº¯æºï¼šå­˜å‚¨æ¨¡å‹äº‹ä»¶
            eventSourcingService.saveEvent(event);

            // æ›´æ–°æ¨¡å‹çŠ¶æ€
            updateModelState(event);

            // è§¦å‘æ¨¡å‹é‡è½½
            if (event.getEventType() == ModelEventType.MODEL_UPDATED ||
                event.getEventType() == ModelEventType.MODEL_VERSION_CHANGED) {
                triggerModelReload(event);
            }

        } catch (Exception e) {
            log.error("å¤„ç†æ¨¡å‹äº‹ä»¶å¤±è´¥", e);
            sendToDeadLetter(message, e);
        }
    }

    private void updateModelState(ModelEvent event) {
        ModelState currentState = modelEventStore.getCurrentModelState(event.getModelId());
        ModelState newState = currentState.applyEvent(event);
        modelEventStore.saveModelState(newState);
    }

    private void triggerModelReload(ModelEvent event) {
        CompletableFuture.runAsync(() -> {
            try {
                inferenceService.reloadModel(event.getModelId());
                log.info("æ¨¡å‹é‡è½½å®Œæˆ: modelId={}", event.getModelId());
            } catch (Exception e) {
                log.error("æ¨¡å‹é‡è½½å¤±è´¥: modelId={}", event.getModelId(), e);
            }
        });
    }

    private void publishInferenceCompletedEvent(InferenceEvent requestEvent, InferenceResult result) {
        InferenceCompletedEvent completedEvent = new InferenceCompletedEvent(
            UUID.randomUUID().toString(),
            requestEvent.getEventId(),
            requestEvent.getModelId(),
            result,
            System.currentTimeMillis()
        );

        Message<InferenceCompletedEvent> message = MessageBuilder
            .withPayload(completedEvent)
            .setHeader("event-type", "inference.completed")
            .setHeader("correlation-id", requestEvent.getEventId())
            .build();

        inferenceOutput().send(message);
    }

    private void publishInferenceFailedEvent(InferenceEvent requestEvent, Throwable throwable) {
        InferenceFailedEvent failedEvent = new InferenceFailedEvent(
            UUID.randomUUID().toString(),
            requestEvent.getEventId(),
            requestEvent.getModelId(),
            throwable.getMessage(),
            System.currentTimeMillis()
        );

        Message<InferenceFailedEvent> message = MessageBuilder
            .withPayload(failedEvent)
            .setHeader("event-type", "inference.failed")
            .setHeader("correlation-id", requestEvent.getEventId())
            .build();

        inferenceOutput().send(message);
    }

    private void publishMetricsEvent(InferenceEvent requestEvent, InferenceResult result) {
        MetricsEvent metricsEvent = new MetricsEvent(
            UUID.randomUUID().toString(),
            requestEvent.getModelId(),
            result.getProcessingTime(),
            result.getConfidence(),
            System.currentTimeMillis()
        );

        Message<MetricsEvent> message = MessageBuilder
            .withPayload(metricsEvent)
            .setHeader("event-type", "metrics.collected")
            .build();

        metricsOutput().send(message);
    }

    private void sendToDeadLetter(Message<?> originalMessage, Exception error) {
        DeadLetterEvent deadLetterEvent = new DeadLetterEvent(
            originalMessage.getPayload(),
            error.getMessage(),
            System.currentTimeMillis()
        );

        Message<DeadLetterEvent> message = MessageBuilder
            .withPayload(deadLetterEvent)
            .copyHeaders(originalMessage.getHeaders())
            .setHeader("error-reason", error.getMessage())
            .build();

        deadLetterOutput().send(message);
    }

    @Autowired
    private MessageChannel inferenceOutput();

    @Autowired
    private MessageChannel metricsOutput();

    @Autowired
    private MessageChannel deadLetterOutput();
}

// æµå¼æ¨ç†æœåŠ¡
@Service
@Slf4j
public class StreamInferenceService {

    private final Map<String, AIModel> modelCache;
    private final StreamProcessor streamProcessor;
    private final ReactiveRedisTemplate<String, String> redisTemplate;

    public StreamInferenceService(StreamProcessor streamProcessor,
                                 ReactiveRedisTemplate<String, String> redisTemplate) {
        this.modelCache = new ConcurrentHashMap<>();
        this.streamProcessor = streamProcessor;
        this.redisTemplate = redisTemplate;
    }

    public CompletableFuture<InferenceResult> streamInference(Object inputData, ModelState modelState) {
        return CompletableFuture.supplyAsync(() -> {
            try {
                // è·å–æ¨¡å‹å®ä¾‹
                AIModel model = getOrLoadModel(modelState);

                // æµå¼å¤„ç†è¾“å…¥æ•°æ®
                Flux<Object> inputStream = convertToStream(inputData);

                // æ‰§è¡Œæµå¼æ¨ç†
                Flux<Object> inferenceStream = streamProcessor.processStream(model, inputStream);

                // æ”¶é›†ç»“æœ
                return collectInferenceResult(inferenceStream);

            } catch (Exception e) {
                log.error("æµå¼æ¨ç†å¤±è´¥", e);
                throw new InferenceException("æµå¼æ¨ç†å¤±è´¥", e);
            }
        });
    }

    private AIModel getOrLoadModel(ModelState modelState) {
        return modelCache.computeIfAbsent(modelState.getModelId(), id -> {
            try {
                return loadModel(modelState);
            } catch (Exception e) {
                log.error("åŠ è½½æ¨¡å‹å¤±è´¥: modelId={}", id, e);
                throw new ModelLoadException("æ¨¡å‹åŠ è½½å¤±è´¥", e);
            }
        });
    }

    private AIModel loadModel(ModelState modelState) {
        // ä»æ¨¡å‹çŠ¶æ€åŠ è½½æ¨¡å‹
        return new AIModel(modelState.getModelPath(), modelState.getVersion());
    }

    private Flux<Object> convertToStream(Object inputData) {
        if (inputData instanceof Flux) {
            return (Flux<Object>) inputData;
        } else if (inputData instanceof List) {
            return Flux.fromIterable((List<Object>) inputData);
        } else {
            return Flux.just(inputData);
        }
    }

    private InferenceResult collectInferenceResult(Flux<Object> inferenceStream) {
        // æ”¶é›†æµå¼æ¨ç†ç»“æœ
        List<Object> results = inferenceStream.collectList().block();

        // è®¡ç®—èšåˆç»“æœ
        Object finalResult = aggregateResults(results);

        return new InferenceResult(
            finalResult.toString(),
            calculateConfidence(results),
            System.currentTimeMillis()
        );
    }

    private Object aggregateResults(List<Object> results) {
        // å®ç°ç»“æœèšåˆé€»è¾‘
        return results.stream().findFirst().orElse("no_result");
    }

    private double calculateConfidence(List<Object> results) {
        // è®¡ç®—ç½®ä¿¡åº¦
        return 0.95;
    }

    public void reloadModel(String modelId) {
        modelCache.remove(modelId);
        // é€šçŸ¥å…¶ä»–èŠ‚ç‚¹é‡è½½æ¨¡å‹
        publishModelReloadEvent(modelId);
    }

    private void publishModelReloadEvent(String modelId) {
        ModelReloadEvent event = new ModelReloadEvent(
            UUID.randomUUID().toString(),
            modelId,
            System.currentTimeMillis()
        );

        // å‘é€æ¨¡å‹é‡è½½äº‹ä»¶
        redisTemplate.convertAndSend("ai:model:reload", event)
            .subscribe(
                success -> log.info("æ¨¡å‹é‡è½½äº‹ä»¶å‘å¸ƒæˆåŠŸ: modelId={}", modelId),
                error -> log.error("æ¨¡å‹é‡è½½äº‹ä»¶å‘å¸ƒå¤±è´¥: modelId={}", modelId, error)
            );
    }

    public boolean isHealthy() {
        return !modelCache.isEmpty();
    }
}

// æµå¤„ç†å™¨
@Component
public class StreamProcessor {

    private final ReactiveKafkaProducerTemplate<String, Object> kafkaProducer;

    public StreamProcessor(ReactiveKafkaProducerTemplate<String, Object> kafkaProducer) {
        this.kafkaProducer = kafkaProducer;
    }

    public Flux<Object> processStream(AIModel model, Flux<Object> inputStream) {
        return inputStream
            .flatMap(input -> processSingleInput(model, input))
            .doOnNext(result -> log.debug("æµå¤„ç†ç»“æœ: {}", result))
            .doOnError(error -> log.error("æµå¤„ç†å‡ºé”™", error));
    }

    private Mono<Object> processSingleInput(AIModel model, Object input) {
        return Mono.fromCallable(() -> {
            // æ‰§è¡Œå•ä¸ªè¾“å…¥çš„æ¨ç†
            return model.predict(input);
        })
        .subscribeOn(Schedulers.parallel())
        .doOnSuccess(result -> {
            // å‘é€ä¸­é—´ç»“æœåˆ°Kafkaï¼ˆå¯é€‰ï¼‰
            publishIntermediateResult(model.getModelId(), input, result);
        });
    }

    private void publishIntermediateResult(String modelId, Object input, Object result) {
        IntermediateResultEvent event = new IntermediateResultEvent(
            modelId,
            input,
            result,
            System.currentTimeMillis()
        );

        kafkaProducer.send("ai.intermediate.results", event)
            .subscribe(
                success -> log.debug("ä¸­é—´ç»“æœå‘å¸ƒæˆåŠŸ"),
                error -> log.error("ä¸­é—´ç»“æœå‘å¸ƒå¤±è´¥", error)
            );
    }
}

// äº‹ä»¶æº¯æºæœåŠ¡
@Service
@Slf4j
public class EventSourcingService {

    private final EventStore eventStore;
    private final AggregateStore aggregateStore;

    public EventSourcingService(EventStore eventStore, AggregateStore aggregateStore) {
        this.eventStore = eventStore;
        this.aggregateStore = aggregateStore;
    }

    public void saveEvent(DomainEvent event) {
        try {
            // ä¿å­˜äº‹ä»¶åˆ°äº‹ä»¶å­˜å‚¨
            eventStore.saveEvent(event);
            log.debug("äº‹ä»¶ä¿å­˜æˆåŠŸ: eventId={}, eventType={}", event.getEventId(), event.getClass().getSimpleName());
        } catch (Exception e) {
            log.error("äº‹ä»¶ä¿å­˜å¤±è´¥: eventId={}", event.getEventId(), e);
            throw new EventPersistenceException("äº‹ä»¶ä¿å­˜å¤±è´¥", e);
        }
    }

    public <T extends AggregateRoot> T getAggregate(String aggregateId, Class<T> aggregateClass) {
        try {
            // èšåˆæ ¹é‡æ„
            List<DomainEvent> events = eventStore.getEvents(aggregateId);
            T aggregate = aggregateClass.getDeclaredConstructor().newInstance();
            aggregate.loadFromHistory(events);
            return aggregate;
        } catch (Exception e) {
            log.error("èšåˆæ ¹é‡æ„å¤±è´¥: aggregateId={}", aggregateId, e);
            throw new AggregateReconstructionException("èšåˆæ ¹é‡æ„å¤±è´¥", e);
        }
    }

    public <T extends AggregateRoot> void saveAggregate(T aggregate) {
        try {
            // è·å–æœªæäº¤çš„äº‹ä»¶
            List<DomainEvent> uncommittedEvents = aggregate.getUncommittedEvents();

            // ä¿å­˜äº‹ä»¶
            for (DomainEvent event : uncommittedEvents) {
                eventStore.saveEvent(event);
            }

            // æ ‡è®°äº‹ä»¶ä¸ºå·²æäº¤
            aggregate.markEventsAsCommitted();

            log.debug("èšåˆæ ¹ä¿å­˜æˆåŠŸ: aggregateId={}, events={}",
                aggregate.getId(), uncommittedEvents.size());

        } catch (Exception e) {
            log.error("èšåˆæ ¹ä¿å­˜å¤±è´¥: aggregateId={}", aggregate.getId(), e);
            throw new AggregatePersistenceException("èšåˆæ ¹ä¿å­˜å¤±è´¥", e);
        }
    }
}

// é…ç½®ç±»
@Configuration
@EnableIntegration
public class StreamProcessingConfiguration {

    @Bean
    public MessageChannel inferenceInput() {
        return new DirectChannel();
    }

    @Bean
    public MessageChannel inferenceOutput() {
        return new DirectChannel();
    }

    @Bean
    public IntegrationFlow inferenceFlow() {
        return IntegrationFlows.from(inferenceInput())
            .transform(this::transformInferenceRequest)
            .handle(this::processInference)
            .channel(inferenceOutput())
            .get();
    }

    private Object transformInferenceRequest(Message<?> message) {
        // è½¬æ¢æ¨ç†è¯·æ±‚
        return message.getPayload();
    }

    private Object processInference(Message<?> message) {
        // å¤„ç†æ¨ç†é€»è¾‘
        return "processed_" + message.getPayload();
    }
}
```

## ğŸ’¡ é¢è¯•æŠ€å·§æç¤º

### Spring Boot AIå¾®æœåŠ¡é¢è¯•è¦ç‚¹ï¼š

1. **æ¶æ„è®¾è®¡**: åˆ†å±‚æ¶æ„ã€æœåŠ¡æ‹†åˆ†ã€APIè®¾è®¡
2. **æœåŠ¡æ²»ç†**: æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡ã€ç†”æ–­å™¨
3. **é…ç½®ç®¡ç†**: é›†ä¸­é…ç½®ã€åŠ¨æ€åˆ·æ–°ã€ç¯å¢ƒéš”ç¦»
4. **äº‹ä»¶é©±åŠ¨**: æµå¤„ç†ã€äº‹ä»¶æº¯æºã€CQRSæ¨¡å¼
5. **ç›‘æ§è¿ç»´**: å¥åº·æ£€æŸ¥ã€æŒ‡æ ‡æ”¶é›†ã€é“¾è·¯è¿½è¸ª

### å¸¸è§é”™è¯¯ï¼š
- ä¸äº†è§£Spring Cloudç”Ÿæ€çš„å®Œæ•´ç»„ä»¶
- ç¼ºä¹å¾®æœåŠ¡æ¶æ„è®¾è®¡ç»éªŒ
- å¿½ç•¥å®¹é”™å’Œé™çº§ç­–ç•¥
- æ²¡æœ‰è€ƒè™‘æ•°æ®ä¸€è‡´æ€§å’Œäº‹åŠ¡ç®¡ç†
- ä¸äº†è§£äº‹ä»¶é©±åŠ¨æ¶æ„çš„å®ç°ç»†èŠ‚

é€šè¿‡è¿™äº›é¢˜ç›®ï¼Œé¢è¯•å®˜èƒ½å…¨é¢è€ƒå¯Ÿå€™é€‰äººå¯¹Spring Bootå¾®æœåŠ¡æ¶æ„å’ŒAIç³»ç»Ÿé›†æˆçš„æ·±åº¦ç†è§£ã€‚