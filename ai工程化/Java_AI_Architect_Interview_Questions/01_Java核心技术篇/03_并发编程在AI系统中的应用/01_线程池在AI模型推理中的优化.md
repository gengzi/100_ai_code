# çº¿ç¨‹æ± åœ¨AIæ¨¡å‹æ¨ç†ä¸­çš„ä¼˜åŒ– (140é¢˜)

## â­ åŸºç¡€é¢˜ (1-42)

### é—®é¢˜1: AIæ¨ç†æœåŠ¡çš„çº¿ç¨‹æ± è®¾è®¡ç­–ç•¥

**é¢è¯•é¢˜**: åœ¨è®¾è®¡AIæ¨ç†æœåŠ¡çš„çº¿ç¨‹æ± æ—¶ï¼Œå¦‚ä½•å¹³è¡¡CPUå¯†é›†å‹å’ŒIOå¯†é›†å‹ä»»åŠ¡ï¼Ÿ

**å£è¯­åŒ–ç­”æ¡ˆ**:
"AIæ¨ç†é€šå¸¸æ˜¯CPUå¯†é›†å‹ï¼Œä½†ä¹Ÿä¼šæœ‰IOæ“ä½œã€‚æˆ‘ä¼šè¿™æ ·è®¾è®¡åˆ†å±‚çº¿ç¨‹æ± ï¼š

```java
public class AIInferenceThreadPool {

    // åˆ†å±‚çº¿ç¨‹æ± æ¶æ„
    public static class LayeredThreadPool {
        private final ThreadPoolExecutor cpuIntensivePool;      // CPUå¯†é›†å‹ä»»åŠ¡
        private final ThreadPoolExecutor ioIntensivePool;       // IOå¯†é›†å‹ä»»åŠ¡
        private final ThreadPoolExecutor mixedTasksPool;        // æ··åˆå‹ä»»åŠ¡
        private final ForkJoinPool computePool;                // è®¡ç®—å¯†é›†å‹å¹¶è¡Œä»»åŠ¡

        public LayeredThreadPool(int cpuCores) {
            // CPUå¯†é›†å‹æ± ï¼šçº¿ç¨‹æ•°=CPUæ ¸å¿ƒæ•°
            this.cpuIntensivePool = new ThreadPoolExecutor(
                cpuCores, cpuCores,
                0L, TimeUnit.MILLISECONDS,
                new LinkedBlockingQueue<>(100),
                new NamedThreadFactory("AI-CPU"),
                new ThreadPoolExecutor.CallerRunsPolicy()
            );

            // IOå¯†é›†å‹æ± ï¼šçº¿ç¨‹æ•°=CPUæ ¸å¿ƒæ•°*2
            this.ioIntensivePool = new ThreadPoolExecutor(
                cpuCores * 2, cpuCores * 4,
                60L, TimeUnit.SECONDS,
                new LinkedBlockingQueue<>(500),
                new NamedThreadFactory("AI-IO"),
                new ThreadPoolExecutor.CallerRunsPolicy()
            );

            // æ··åˆä»»åŠ¡æ± ï¼šä¸­ç­‰å¤§å°
            this.mixedTasksPool = new ThreadPoolExecutor(
                cpuCores, cpuCores * 2,
                30L, TimeUnit.SECONDS,
                new LinkedBlockingQueue<>(200),
                new NamedThreadFactory("AI-MIXED"),
                new ThreadPoolExecutor.AbortPolicy()
            );

            // å¹¶è¡Œè®¡ç®—æ± ï¼šä½¿ç”¨å·¥ä½œçªƒå–
            this.computePool = new ForkJoinPool(cpuCores);
        }

        // AIæ¨¡å‹æ¨ç† - CPUå¯†é›†å‹
        public CompletableFuture<InferenceResult> submitInference(InferenceTask task) {
            return CompletableFuture.supplyAsync(() -> {
                return task.execute();  // æ‰§è¡Œæ¨¡å‹æ¨ç†
            }, cpuIntensivePool);
        }

        // æ¨¡å‹åŠ è½½ - IOå¯†é›†å‹
        public CompletableFuture<Model> loadModel(String modelPath) {
            return CompletableFuture.supplyAsync(() -> {
                return ModelLoader.load(modelPath);  // ä»ç£ç›˜åŠ è½½æ¨¡å‹
            }, ioIntensivePool);
        }

        // æ‰¹é‡æ¨ç† - ä½¿ç”¨å¹¶è¡Œè®¡ç®—
        public CompletableFuture<List<InferenceResult>> submitBatchInference(
                List<InferenceTask> tasks) {

            return CompletableFuture.supplyAsync(() -> {
                return tasks.parallelStream()
                    .map(InferenceTask::execute)
                    .collect(Collectors.toList());
            }, computePool);
        }

        // æ•°æ®é¢„å¤„ç† - æ··åˆå‹ä»»åŠ¡
        public CompletableFuture<ProcessedData> preprocessData(RawData data) {
            return CompletableFuture.supplyAsync(() -> {
                // åŒ…å«IO(è¯»æ–‡ä»¶)å’Œè®¡ç®—(æ•°æ®è½¬æ¢)
                DataPreprocessor preprocessor = new DataPreprocessor();
                return preprocessor.process(data);
            }, mixedTasksPool);
        }

        // åŠ¨æ€è°ƒæ•´çº¿ç¨‹æ± å¤§å°
        public void adjustPoolSize(double cpuUtilization, double queueSize) {
            if (cpuUtilization < 0.5 && queueSize > 0.8) {
                // CPUåˆ©ç”¨ç‡ä½ï¼Œé˜Ÿåˆ—ç§¯å‹å¤šï¼Œå¢åŠ çº¿ç¨‹
                int currentSize = cpuIntensivePool.getCorePoolSize();
                int newSize = Math.min(currentSize + 2, Runtime.getRuntime().availableProcessors());
                cpuIntensivePool.setCorePoolSize(newSize);
                cpuIntensivePool.setMaximumPoolSize(newSize);
                System.out.println("å¢åŠ CPUçº¿ç¨‹æ± å¤§å°åˆ°: " + newSize);
            } else if (cpuUtilization > 0.9) {
                // CPUåˆ©ç”¨ç‡é«˜ï¼Œå‡å°‘çº¿ç¨‹é¿å…ä¸Šä¸‹æ–‡åˆ‡æ¢
                int currentSize = cpuIntensivePool.getCorePoolSize();
                int newSize = Math.max(currentSize - 1, Runtime.getRuntime().availableProcessors() / 2);
                cpuIntensivePool.setCorePoolSize(newSize);
                System.out.println("å‡å°‘CPUçº¿ç¨‹æ± å¤§å°åˆ°: " + newSize);
            }
        }
    }

    // å‘½åçº¿ç¨‹å·¥å‚
    public static class NamedThreadFactory implements ThreadFactory {
        private final AtomicInteger threadNumber = new AtomicInteger(1);
        private final String namePrefix;

        public NamedThreadFactory(String namePrefix) {
            this.namePrefix = namePrefix;
        }

        @Override
        public Thread newThread(Runnable r) {
            Thread t = new Thread(r, namePrefix + "-" + threadNumber.getAndIncrement());
            t.setDaemon(false);
            return t;
        }
    }

    // AIæ¨ç†ä»»åŠ¡
    public static class InferenceTask {
        private final String modelId;
        private final Object input;
        private final int priority;

        public InferenceTask(String modelId, Object input, int priority) {
            this.modelId = modelId;
            this.input = input;
            this.priority = priority;
        }

        public InferenceResult execute() {
            // æ¨¡æ‹Ÿæ¨ç†è®¡ç®—
            try {
                Thread.sleep(50 + ThreadLocalRandom.current().nextInt(100));
                return new InferenceResult("result_for_" + modelId, 0.95);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                return new InferenceResult("error", 0.0);
            }
        }

        // getters...
        public String getModelId() { return modelId; }
        public Object getInput() { return input; }
        public int getPriority() { return priority; }
    }

    // æ¨ç†ç»“æœ
    public static class InferenceResult {
        private final String result;
        private final double confidence;

        public InferenceResult(String result, double confidence) {
            this.result = result;
            this.confidence = confidence;
        }

        // getters...
        public String getResult() { return result; }
        public double getConfidence() { return confidence; }
    }
}
```

## â­â­ è¿›é˜¶é¢˜ (43-98)

### é—®é¢˜43: è‡ªé€‚åº”çº¿ç¨‹æ± åœ¨åŠ¨æ€AIè´Ÿè½½ä¸­çš„åº”ç”¨

**é¢è¯•é¢˜**: å¦‚ä½•è®¾è®¡ä¸€ä¸ªèƒ½æ ¹æ®AIæ¨ç†è´Ÿè½½è‡ªåŠ¨è°ƒæ•´çš„æ™ºèƒ½çº¿ç¨‹æ± ï¼Ÿ

**å£è¯­åŒ–ç­”æ¡ˆ**:
"è‡ªé€‚åº”çº¿ç¨‹æ± å¯¹AIæœåŠ¡å¾ˆé‡è¦ï¼Œå› ä¸ºæ¨ç†è´Ÿè½½ä¼šæœ‰å³°å€¼å’Œä½è°·ã€‚æˆ‘ä¼šè®¾è®¡ä¸€ä¸ªåŸºäºæŒ‡æ ‡åé¦ˆçš„è‡ªé€‚åº”ç³»ç»Ÿï¼š

```java
public class AdaptiveAIInferencePool {

    // è‡ªé€‚åº”çº¿ç¨‹æ± ç®¡ç†å™¨
    public static class AdaptiveThreadPoolManager {
        private final ThreadPoolExecutor inferencePool;
        private final AtomicLong completedTasks = new AtomicLong(0);
        private final AtomicLong totalExecutionTime = new AtomicLong(0);
        private final AtomicLong rejectedTasks = new AtomicLong(0);
        private volatile long lastAdjustmentTime = System.currentTimeMillis();

        // æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
        private final PerformanceMetrics metrics;
        private final ScheduledExecutorService monitor;

        public AdaptiveThreadPoolManager(int minThreads, int maxThreads) {
            this.metrics = new PerformanceMetrics();
            this.monitor = Executors.newSingleThreadScheduledExecutor();

            // åˆ›å»ºå¯åŠ¨æ€è°ƒæ•´çš„çº¿ç¨‹æ± 
            this.inferencePool = new ThreadPoolExecutor(
                minThreads, maxThreads,
                60L, TimeUnit.SECONDS,
                new PriorityBlockingQueue<>(100, (r1, r2) -> {
                    if (r1 instanceof PriorityTask && r2 instanceof PriorityTask) {
                        PriorityTask pt1 = (PriorityTask) r1;
                        PriorityTask pt2 = (PriorityTask) r2;
                        return Integer.compare(pt2.getPriority(), pt1.getPriority());
                    }
                    return 0;
                }),
                new AdaptiveThreadFactory(),
                new AdaptiveRejectionHandler()
            );

            startMonitoring();
        }

        // å¯åŠ¨æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨è°ƒæ•´
        private void startMonitoring() {
            monitor.scheduleAtFixedRate(() -> {
                try {
                    collectMetrics();
                    adjustThreadPoolSize();
                } catch (Exception e) {
                    System.err.println("è‡ªé€‚åº”è°ƒæ•´å‡ºé”™: " + e.getMessage());
                }
            }, 0, 5, TimeUnit.SECONDS);
        }

        // æ”¶é›†æ€§èƒ½æŒ‡æ ‡
        private void collectMetrics() {
            ThreadPoolStats stats = getCurrentStats();
            metrics.addMeasurement(stats);

            // æ‰“å°å½“å‰çŠ¶æ€
            if (metrics.getMeasurementCount() % 12 == 0) { // æ¯åˆ†é’Ÿæ‰“å°ä¸€æ¬¡
                System.out.printf(
                    "çº¿ç¨‹æ± çŠ¶æ€: æ ¸å¿ƒ=%d, æœ€å¤§=%d, æ´»è·ƒ=%d, é˜Ÿåˆ—=%d, å®Œæˆ=%d, å¹³å‡å“åº”=%.2fms%n",
                    stats.getCorePoolSize(),
                    stats.getMaximumPoolSize(),
                    stats.getActiveThreads(),
                    stats.getQueueSize(),
                    stats.getCompletedTasks(),
                    metrics.getAverageResponseTime()
                );
            }
        }

        // æ™ºèƒ½è°ƒæ•´çº¿ç¨‹æ± å¤§å°
        private void adjustThreadPoolSize() {
            long currentTime = System.currentTimeMillis();
            if (currentTime - lastAdjustmentTime < 30000) { // 30ç§’è°ƒæ•´é—´éš”
                return;
            }

            ThreadPoolStats currentStats = getCurrentStats();
            AdjustmentDecision decision = makeAdjustmentDecision(currentStats);

            if (decision.shouldAdjust()) {
                applyAdjustment(decision);
                lastAdjustmentTime = currentTime;
            }
        }

        // è°ƒæ•´å†³ç­–ç®—æ³•
        private AdjustmentDecision makeAdjustmentDecision(ThreadPoolStats stats) {
            double avgResponseTime = metrics.getAverageResponseTime();
            double cpuUtilization = getCpuUtilization();
            double queueRatio = (double) stats.getQueueSize() / stats.getMaximumPoolSize();
            double rejectionRate = metrics.getRejectionRate();

            // å†³ç­–é€»è¾‘
            if (rejectionRate > 0.05 || queueRatio > 0.8) {
                // æ‹’ç»ç‡æˆ–é˜Ÿåˆ—ç§¯å‹ä¸¥é‡ï¼Œéœ€è¦æ‰©å®¹
                int newSize = Math.min(
                    stats.getMaximumPoolSize() + 2,
                    Runtime.getRuntime().availableProcessors() * 4
                );
                return new AdjustmentDecision(
                    Action.SCALE_UP,
                    newSize,
                    String.format("é˜Ÿåˆ—ç§¯å‹ä¸¥é‡(%.1f%%)æˆ–æ‹’ç»ç‡é«˜(%.1f%%)", queueRatio * 100, rejectionRate * 100)
                );
            } else if (avgResponseTime > 200 && cpuUtilization < 0.8) {
                // å“åº”æ—¶é—´é«˜ä½†CPUä¸é¥±å’Œï¼Œå¢åŠ çº¿ç¨‹
                int newSize = Math.min(
                    stats.getMaximumPoolSize() + 1,
                    Runtime.getRuntime().availableProcessors() * 3
                );
                return new AdjustmentDecision(
                    Action.SCALE_UP,
                    newSize,
                    String.format("å“åº”æ—¶é—´è¿‡é•¿(%.1fms)ä½†CPUåˆ©ç”¨ç‡ä½(%.1f%%)", avgResponseTime, cpuUtilization * 100)
                );
            } else if (cpuUtilization > 0.9 && avgResponseTime > 300) {
                // CPUè¿‡è½½ä¸”å“åº”æ—¶é—´æ…¢ï¼Œå‡å°‘çº¿ç¨‹é¿å…ä¸Šä¸‹æ–‡åˆ‡æ¢
                int newSize = Math.max(
                    stats.getMaximumPoolSize() - 1,
                    Runtime.getRuntime().availableProcessors()
                );
                return new AdjustmentDecision(
                    Action.SCALE_DOWN,
                    newSize,
                    String.format("CPUè¿‡è½½(%.1f%%)ä¸”å“åº”æ—¶é—´è¿‡é•¿(%.1fms)", cpuUtilization * 100, avgResponseTime)
                );
            } else if (stats.getActiveThreads() < stats.getCorePoolSize() * 0.5 &&
                      queueRatio < 0.1 && avgResponseTime < 50) {
                // çº¿ç¨‹åˆ©ç”¨ç‡ä½ï¼Œé˜Ÿåˆ—ç©ºé—²ï¼Œå“åº”æ—¶é—´å¿«ï¼Œå¯ä»¥ç¼©å®¹
                int newSize = Math.max(
                    stats.getMaximumPoolSize() - 1,
                    Runtime.getRuntime().availableProcessors()
                );
                return new AdjustmentDecision(
                    Action.SCALE_DOWN,
                    newSize,
                    "è´Ÿè½½è¾ƒä½ï¼ŒèŠ‚çœèµ„æº"
                );
            }

            return new AdjustmentDecision(Action.NO_CHANGE, stats.getMaximumPoolSize(), "æ€§èƒ½è‰¯å¥½ï¼Œæ— éœ€è°ƒæ•´");
        }

        // åº”ç”¨è°ƒæ•´
        private void applyAdjustment(AdjustmentDecision decision) {
            switch (decision.getAction()) {
                case SCALE_UP:
                    int oldSize = inferencePool.getMaximumPoolSize();
                    inferencePool.setMaximumPoolSize(decision.getNewSize());
                    inferencePool.setCorePoolSize(decision.getNewSize());
                    System.out.printf("æ‰©å®¹: %d -> %d (%s)%n", oldSize, decision.getNewSize(), decision.getReason());
                    break;

                case SCALE_DOWN:
                    oldSize = inferencePool.getMaximumPoolSize();
                    inferencePool.setCorePoolSize(decision.getNewSize());
                    inferencePool.setMaximumPoolSize(decision.getNewSize());
                    System.out.printf("ç¼©å®¹: %d -> %d (%s)%n", oldSize, decision.getNewSize(), decision.getReason());
                    break;

                case NO_CHANGE:
                    // æ— æ“ä½œ
                    break;
            }
        }

        // æäº¤AIæ¨ç†ä»»åŠ¡
        public CompletableFuture<InferenceResult> submitInference(
                String modelId, Object input, int priority) {

            PriorityTask task = new PriorityTask(() -> {
                long startTime = System.currentTimeMillis();
                InferenceResult result = performInference(modelId, input);
                long executionTime = System.currentTimeMillis() - startTime;

                // æ›´æ–°æŒ‡æ ‡
                completedTasks.incrementAndGet();
                totalExecutionTime.addAndGet(executionTime);
                metrics.recordResponseTime(executionTime);

                return result;
            }, priority);

            try {
                return CompletableFuture.supplyAsync(task::call, inferencePool);
            } catch (RejectedExecutionException e) {
                rejectedTasks.incrementAndGet();
                metrics.recordRejection();
                return CompletableFuture.completedFuture(
                    new InferenceResult("rejected", 0.0)
                );
            }
        }

        private InferenceResult performInference(String modelId, Object input) {
            // æ¨¡æ‹ŸAIæ¨ç†è¿‡ç¨‹
            try {
                Thread.sleep(20 + ThreadLocalRandom.current().nextInt(80));
                return new InferenceResult("result_for_" + modelId, 0.95);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                return new InferenceResult("interrupted", 0.0);
            }
        }

        private ThreadPoolStats getCurrentStats() {
            return new ThreadPoolStats(
                inferencePool.getCorePoolSize(),
                inferencePool.getMaximumPoolSize(),
                inferencePool.getActiveCount(),
                inferencePool.getQueue().size(),
                inferencePool.getCompletedTaskCount()
            );
        }

        private double getCpuUtilization() {
            OperatingSystemMXBean osBean = ManagementFactory.getOperatingSystemMXBean();
            return osBean.getProcessCpuLoad();
        }

        public void shutdown() {
            monitor.shutdown();
            inferencePool.shutdown();
        }
    }

    // ä¼˜å…ˆçº§ä»»åŠ¡åŒ…è£…å™¨
    public static class PriorityTask implements Callable<InferenceResult>, Comparable<PriorityTask> {
        private final Callable<InferenceResult> task;
        private final int priority;
        private final long timestamp;

        public PriorityTask(Callable<InferenceResult> task, int priority) {
            this.task = task;
            this.priority = priority;
            this.timestamp = System.nanoTime();
        }

        @Override
        public InferenceResult call() throws Exception {
            return task.call();
        }

        @Override
        public int compareTo(PriorityTask other) {
            // é«˜ä¼˜å…ˆçº§å…ˆæ‰§è¡Œï¼Œç›¸åŒä¼˜å…ˆçº§æŒ‰æ—¶é—´æ’åº
            int priorityCompare = Integer.compare(other.priority, this.priority);
            if (priorityCompare != 0) {
                return priorityCompare;
            }
            return Long.compare(this.timestamp, other.timestamp);
        }

        public int getPriority() { return priority; }
    }

    // æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
    public static class PerformanceMetrics {
        private final Queue<Double> responseTimes = new ConcurrentLinkedQueue<>();
        private final Queue<Long> rejectionTimestamps = new ConcurrentLinkedQueue<>();
        private final AtomicInteger measurementCount = new AtomicInteger(0);

        public void addMeasurement(ThreadPoolStats stats) {
            measurementCount.incrementAndGet();
        }

        public void recordResponseTime(long responseTime) {
            responseTimes.offer((double) responseTime);
            // ä¿æŒæœ€è¿‘1000ä¸ªæ ·æœ¬
            while (responseTimes.size() > 1000) {
                responseTimes.poll();
            }
        }

        public void recordRejection() {
            rejectionTimestamps.offer(System.currentTimeMillis());
            while (rejectionTimestamps.size() > 100) {
                rejectionTimestamps.poll();
            }
        }

        public double getAverageResponseTime() {
            if (responseTimes.isEmpty()) return 0.0;

            double sum = 0.0;
            int count = 0;
            for (Double time : responseTimes) {
                sum += time;
                count++;
            }
            return sum / count;
        }

        public double getRejectionRate() {
            long currentTime = System.currentTimeMillis();
            long timeWindow = 60000; // 1åˆ†é’Ÿçª—å£

            // è®¡ç®—æ—¶é—´çª—å£å†…çš„æ‹’ç»æ¬¡æ•°
            int rejectionsInWindow = 0;
            for (Long timestamp : rejectionTimestamps) {
                if (currentTime - timestamp <= timeWindow) {
                    rejectionsInWindow++;
                }
            }

            // ç®€åŒ–è®¡ç®—ï¼šå‡è®¾æ€»ä»»åŠ¡æ•°ä¸ºæ‹’ç»æ¬¡æ•°çš„20å€
            long totalTasks = rejectionsInWindow * 20;
            return totalTasks > 0 ? (double) rejectionsInWindow / totalTasks : 0.0;
        }

        public int getMeasurementCount() {
            return measurementCount.get();
        }
    }

    // è°ƒæ•´å†³ç­–
    public static class AdjustmentDecision {
        private final Action action;
        private final int newSize;
        private final String reason;

        public AdjustmentDecision(Action action, int newSize, String reason) {
            this.action = action;
            this.newSize = newSize;
            this.reason = reason;
        }

        public boolean shouldAdjust() {
            return action != Action.NO_CHANGE;
        }

        // getters...
        public Action getAction() { return action; }
        public int getNewSize() { return newSize; }
        public String getReason() { return reason; }
    }

    public enum Action {
        SCALE_UP, SCALE_DOWN, NO_CHANGE
    }

    // è‡ªé€‚åº”çº¿ç¨‹å·¥å‚
    public static class AdaptiveThreadFactory implements ThreadFactory {
        private final AtomicInteger threadNumber = new AtomicInteger(1);

        @Override
        public Thread newThread(Runnable r) {
            Thread t = new Thread(r, "AI-Adaptive-" + threadNumber.getAndIncrement());
            t.setPriority(Thread.NORM_PRIORITY);
            t.setDaemon(false);
            return t;
        }
    }

    // è‡ªé€‚åº”æ‹’ç»å¤„ç†å™¨
    public static class AdaptiveRejectionHandler implements RejectedExecutionHandler {
        private final AtomicInteger rejectedCount = new AtomicInteger(0);

        @Override
        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
            rejectedCount.incrementAndGet();

            if (r instanceof PriorityTask) {
                PriorityTask task = (PriorityTask) r;
                if (task.getPriority() > 5) {
                    // é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼Œå°è¯•åœ¨è°ƒç”¨çº¿ç¨‹æ‰§è¡Œ
                    try {
                        r.run();
                    } catch (Exception e) {
                        System.err.println("è°ƒç”¨çº¿ç¨‹æ‰§è¡Œå¤±è´¥: " + e.getMessage());
                    }
                } else {
                    // ä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼Œç›´æ¥æ‹’ç»
                    throw new RejectedExecutionException("ä»»åŠ¡è¢«æ‹’ç»ï¼Œå½“å‰é˜Ÿåˆ—å·²æ»¡");
                }
            } else {
                throw new RejectedExecutionException("ä»»åŠ¡è¢«æ‹’ç»");
            }
        }

        public int getRejectedCount() {
            return rejectedCount.get();
        }
    }

    // çº¿ç¨‹æ± ç»Ÿè®¡ä¿¡æ¯
    public static class ThreadPoolStats {
        private final int corePoolSize;
        private final int maximumPoolSize;
        private final int activeThreads;
        private final int queueSize;
        private final long completedTasks;

        public ThreadPoolStats(int corePoolSize, int maximumPoolSize,
                             int activeThreads, int queueSize, long completedTasks) {
            this.corePoolSize = corePoolSize;
            this.maximumPoolSize = maximumPoolSize;
            this.activeThreads = activeThreads;
            this.queueSize = queueSize;
            this.completedTasks = completedTasks;
        }

        // getters...
        public int getCorePoolSize() { return corePoolSize; }
        public int getMaximumPoolSize() { return maximumPoolSize; }
        public int getActiveThreads() { return activeThreads; }
        public int getQueueSize() { return queueSize; }
        public long getCompletedTasks() { return completedTasks; }
    }
}
```

## â­â­â­ ä¸“å®¶é¢˜ (99-140)

### é—®é¢˜99: åŸºäºæœºå™¨å­¦ä¹ çš„çº¿ç¨‹æ± å‚æ•°è‡ªåŠ¨è°ƒä¼˜

**é¢è¯•é¢˜**: å¦‚ä½•è®¾è®¡ä¸€ä¸ªåŸºäºæœºå™¨å­¦ä¹ çš„æ™ºèƒ½çº¿ç¨‹æ± è°ƒä¼˜ç³»ç»Ÿï¼Ÿ

**å£è¯­åŒ–ç­”æ¡ˆ**:
"è¿™å¾ˆæœ‰æ„æ€ï¼æˆ‘ä¼šç”¨æœºå™¨å­¦ä¹ æ¥é¢„æµ‹æœ€ä¼˜çš„çº¿ç¨‹æ± å‚æ•°ï¼Œå®ç°çœŸæ­£çš„æ™ºèƒ½è°ƒä¼˜ï¼š

```java
public class MLBasedThreadPoolOptimizer {

    // çº¿ç¨‹æ± å‚æ•°ä¼˜åŒ–å™¨
    public static class MLThreadPoolOptimizer {
        private final ThreadPoolExecutor inferencePool;
        private final FeatureCollector featureCollector;
        private final ThreadPoolSizePredictor predictor;
        private final PerformanceHistory history;

        public MLThreadPoolOptimizer(int initialThreads) {
            this.inferencePool = createDynamicThreadPool(initialThreads);
            this.featureCollector = new FeatureCollector();
            this.predictor = new ThreadPoolSizePredictor();
            this.history = new PerformanceHistory();

            startAutoOptimization();
        }

        private ThreadPoolExecutor createDynamicThreadPool(int initialSize) {
            return new ThreadPoolExecutor(
                initialSize, initialSize * 4,
                60L, TimeUnit.SECONDS,
                new LinkedBlockingQueue<>(1000),
                new MLThreadFactory(),
                new MLRejectionHandler()
            );
        }

        // å¯åŠ¨è‡ªåŠ¨ä¼˜åŒ–
        private void startAutoOptimization() {
            ScheduledExecutorService optimizer = Executors.newSingleThreadScheduledExecutor();

            optimizer.scheduleAtFixedRate(() -> {
                try {
                    performMLBasedOptimization();
                } catch (Exception e) {
                    System.err.println("MLä¼˜åŒ–å‡ºé”™: " + e.getMessage());
                }
            }, 0, 30, TimeUnit.SECONDS);
        }

        // åŸºäºæœºå™¨å­¦ä¹ çš„ä¼˜åŒ–
        private void performMLBasedOptimization() {
            // 1. æ”¶é›†å½“å‰ç‰¹å¾
            FeatureVector currentFeatures = featureCollector.collectFeatures(inferencePool);

            // 2. è·å–å†å²æ€§èƒ½æ•°æ®
            List<PerformanceSnapshot> recentHistory = history.getRecentSnapshots(100);

            // 3. é¢„æµ‹æœ€ä¼˜çº¿ç¨‹æ± å¤§å°
            int optimalSize = predictor.predictOptimalSize(currentFeatures, recentHistory);

            // 4. åº”ç”¨ä¼˜åŒ–å†³ç­–
            applyOptimalSize(optimalSize);

            // 5. è®°å½•ä¼˜åŒ–ç»“æœç”¨äºä¸‹æ¬¡å­¦ä¹ 
            recordOptimizationResult(currentFeatures, optimalSize);
        }

        // æ”¶é›†ç‰¹å¾å‘é‡
        public static class FeatureCollector {
            private final OperatingSystemMXBean osBean = ManagementFactory.getOperatingSystemMXBean();
            private final MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
            private final ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();

            public FeatureVector collectFeatures(ThreadPoolExecutor pool) {
                FeatureVector features = new FeatureVector();

                // ç³»ç»Ÿçº§ç‰¹å¾
                features.setCpuUtilization(osBean.getProcessCpuLoad());
                features.setCpuCoreCount(osBean.getAvailableProcessors());
                features.setSystemLoadAverage(osBean.getSystemLoadAverage());

                // å†…å­˜ç‰¹å¾
                MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage();
                features.setHeapUtilization((double) heapUsage.getUsed() / heapUsage.getMax());
                features.setNonHeapUtilization((double) memoryBean.getNonHeapMemoryUsage().getUsed() /
                                                memoryBean.getNonHeapMemoryUsage().getMax());

                // çº¿ç¨‹æ± ç‰¹å¾
                features.setActiveThreads(pool.getActiveCount());
                features.setCorePoolSize(pool.getCorePoolSize());
                features.setMaximumPoolSize(pool.getMaximumPoolSize());
                features.setQueueSize(pool.getQueue().size());
                features.setCompletedTasks(pool.getCompletedTaskCount());

                // æ—¶é—´ç‰¹å¾
                long currentTime = System.currentTimeMillis();
                features.setHourOfDay(getHourOfDay(currentTime));
                features.setDayOfWeek(getDayOfWeek(currentTime));

                // æ€§èƒ½æŒ‡æ ‡ç‰¹å¾
                double avgResponseTime = calculateAverageResponseTime(pool);
                features.setAverageResponseTime(avgResponseTime);
                features.setThroughput(calculateThroughput(pool));

                return features;
            }

            private double calculateAverageResponseTime(ThreadPoolExecutor pool) {
                // ç®€åŒ–å®ç°ï¼Œå®é™…ä¸­åº”è¯¥ç”¨æ›´ç²¾ç¡®çš„æµ‹é‡
                return 50.0 + Math.random() * 100.0; // ms
            }

            private double calculateThroughput(ThreadPoolExecutor pool) {
                long completed = pool.getCompletedTaskCount();
                return completed > 0 ? (double) completed / 60.0 : 0.0; // tasks per minute
            }

            private int getHourOfDay(long timestamp) {
                return (int) ((timestamp / (1000 * 60 * 60)) % 24);
            }

            private int getDayOfWeek(long timestamp) {
                return (int) ((timestamp / (1000 * 60 * 60 * 24)) % 7);
            }
        }

        // ç‰¹å¾å‘é‡
        public static class FeatureVector {
            private double cpuUtilization;
            private int cpuCoreCount;
            private double systemLoadAverage;
            private double heapUtilization;
            private double nonHeapUtilization;
            private int activeThreads;
            private int corePoolSize;
            private int maximumPoolSize;
            private int queueSize;
            private long completedTasks;
            private int hourOfDay;
            private int dayOfWeek;
            private double averageResponseTime;
            private double throughput;

            // è½¬æ¢ä¸ºæœºå™¨å­¦ä¹ ç‰¹å¾æ•°ç»„
            public double[] toArray() {
                return new double[] {
                    cpuUtilization,
                    cpuCoreCount / 16.0,  // å½’ä¸€åŒ–
                    systemLoadAverage / 8.0,  // å½’ä¸€åŒ–
                    heapUtilization,
                    nonHeapUtilization,
                    activeThreads / 100.0,  // å½’ä¸€åŒ–
                    corePoolSize / 100.0,
                    maximumPoolSize / 100.0,
                    queueSize / 1000.0,
                    Math.log(Math.max(1, completedTasks)), // å¯¹æ•°å˜æ¢
                    hourOfDay / 24.0,
                    dayOfWeek / 7.0,
                    averageResponseTime / 1000.0,  // å½’ä¸€åŒ–åˆ°ç§’
                    throughput / 1000.0  // å½’ä¸€åŒ–
                };
            }

            // getters and setters...
            public double getCpuUtilization() { return cpuUtilization; }
            public void setCpuUtilization(double cpuUtilization) { this.cpuUtilization = cpuUtilization; }
            // ... å…¶ä»–getter/setteræ–¹æ³•
        }

        // çº¿ç¨‹æ± å¤§å°é¢„æµ‹å™¨
        public static class ThreadPoolSizePredictor {
            private final SimpleMLModel model;
            private final List<TrainingExample> trainingData;

            public ThreadPoolSizePredictor() {
                this.model = new SimpleMLModel();
                this.trainingData = new ArrayList<>();
                initializeWithBaselineData();
            }

            private void initializeWithBaselineData() {
                // åŸºäºç»éªŒçš„åŸºçº¿æ•°æ®
                trainingData.addAll(Arrays.asList(
                    // é«˜CPUåˆ©ç”¨ç‡ï¼Œé«˜é˜Ÿåˆ—ï¼Œéœ€è¦æ›´å¤šçº¿ç¨‹
                    new TrainingExample(
                        new double[]{0.9, 8, 2.0, 0.8, 0.3, 50, 8, 32, 500, 10, 14, 5, 0.2, 0.5},
                        48  // é¢„æœŸçº¿ç¨‹æ•°
                    ),
                    // ä½CPUåˆ©ç”¨ç‡ï¼Œä½é˜Ÿåˆ—ï¼Œå‡å°‘çº¿ç¨‹
                    new TrainingExample(
                        new double[]{0.2, 8, 0.5, 0.4, 0.1, 5, 4, 16, 10, 5, 2, 1, 0.05, 0.1},
                        8   // é¢„æœŸçº¿ç¨‹æ•°
                    ),
                    // ä¸­ç­‰è´Ÿè½½
                    new TrainingExample(
                        new double[]{0.6, 8, 1.2, 0.6, 0.2, 20, 8, 24, 100, 8, 10, 3, 0.1, 0.3},
                        24  // é¢„æœŸçº¿ç¨‹æ•°
                    )
                ));

                model.train(trainingData);
            }

            public int predictOptimalSize(FeatureVector features,
                                          List<PerformanceSnapshot> history) {
                double[] featureArray = features.toArray();

                // åŸºäºå½“å‰ç‰¹å¾é¢„æµ‹
                int basePrediction = (int) model.predict(featureArray);

                // è€ƒè™‘å†å²è¶‹åŠ¿è°ƒæ•´
                double trendAdjustment = calculateTrendAdjustment(history);
                int adjustedPrediction = (int) (basePrediction * (1 + trendAdjustment));

                // åº”ç”¨çº¦æŸæ¡ä»¶
                int minSize = Math.max(2, Runtime.getRuntime().availableProcessors());
                int maxSize = Runtime.getRuntime().availableProcessors() * 6;

                return Math.max(minSize, Math.min(maxSize, adjustedPrediction));
            }

            private double calculateTrendAdjustment(List<PerformanceSnapshot> history) {
                if (history.size() < 10) return 0.0;

                // åˆ†ææœ€è¿‘çš„æ€§èƒ½è¶‹åŠ¿
                double recentAvgResponse = history.stream()
                    .skip(history.size() - 10)
                    .mapToDouble(PerformanceSnapshot::getAverageResponseTime)
                    .average().orElse(0.0);

                double historicalAvgResponse = history.stream()
                    .mapToDouble(PerformanceSnapshot::getAverageResponseTime)
                    .average().orElse(0.0);

                if (recentAvgResponse > historicalAvgResponse * 1.2) {
                    return 0.3; // å¢åŠ 30%
                } else if (recentAvgResponse < historicalAvgResponse * 0.8) {
                    return -0.2; // å‡å°‘20%
                }

                return 0.0; // æ— è°ƒæ•´
            }

            public void addTrainingData(FeatureVector features, int optimalSize) {
                trainingData.add(new TrainingExample(features.toArray(), optimalSize));

                // å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹
                if (trainingData.size() % 20 == 0) {
                    model.train(trainingData);
                }
            }
        }

        // ç®€åŒ–çš„æœºå™¨å­¦ä¹ æ¨¡å‹
        public static class SimpleMLModel {
            private double[] weights;
            private double bias;

            public SimpleMLModel() {
                this.weights = new double[14]; // ç‰¹å¾ç»´åº¦
                this.bias = 0.0;
                initializeWeights();
            }

            private void initializeWeights() {
                Random random = new Random(42);
                for (int i = 0; i < weights.length; i++) {
                    weights[i] = random.nextGaussian() * 0.1;
                }
                bias = random.nextGaussian() * 0.1;
            }

            public void train(List<TrainingExample> data) {
                // ç®€å•çš„çº¿æ€§å›å½’è®­ç»ƒ
                int iterations = 1000;
                double learningRate = 0.01;

                for (int iter = 0; iter < iterations; iter++) {
                    for (TrainingExample example : data) {
                        double prediction = predict(example.getFeatures());
                        double error = prediction - example.getTarget();

                        // æ¢¯åº¦ä¸‹é™æ›´æ–°
                        for (int i = 0; i < weights.length; i++) {
                            weights[i] -= learningRate * error * example.getFeatures()[i];
                        }
                        bias -= learningRate * error;
                    }
                }

                System.out.println("MLæ¨¡å‹é‡æ–°è®­ç»ƒå®Œæˆ");
            }

            public double predict(double[] features) {
                double result = bias;
                for (int i = 0; i < weights.length && i < features.length; i++) {
                    result += weights[i] * features[i];
                }

                // åº”ç”¨æ¿€æ´»å‡½æ•°ç¡®ä¿æ­£å€¼
                return Math.max(2.0, result);
            }
        }

        // è®­ç»ƒæ ·æœ¬
        public static class TrainingExample {
            private final double[] features;
            private final double target;

            public TrainingExample(double[] features, double target) {
                this.features = features.clone();
                this.target = target;
            }

            // getters...
            public double[] getFeatures() { return features; }
            public double getTarget() { return target; }
        }

        // åº”ç”¨æœ€ä¼˜çº¿ç¨‹æ± å¤§å°
        private void applyOptimalSize(int optimalSize) {
            int currentSize = inferencePool.getMaximumPoolSize();

            if (optimalSize != currentSize) {
                System.out.printf("MLä¼˜åŒ–: çº¿ç¨‹æ± å¤§å° %d -> %d%n", currentSize, optimalSize);

                // å¹³æ»‘è°ƒæ•´ï¼Œé¿å…çªå˜
                int stepSize = Integer.signum(optimalSize - currentSize) * 2;
                int newSize = currentSize + stepSize;

                newSize = Math.max(2, Math.min(optimalSize, newSize));

                inferencePool.setCorePoolSize(newSize);
                inferencePool.setMaximumPoolSize(newSize);
            }
        }

        // è®°å½•ä¼˜åŒ–ç»“æœ
        private void recordOptimizationResult(FeatureVector features, int appliedSize) {
            PerformanceSnapshot snapshot = new PerformanceSnapshot(
                features,
                appliedSize,
                inferencePool.getActiveCount(),
                inferencePool.getQueue().size()
            );

            history.addSnapshot(snapshot);

            // å»¶è¿Ÿè¯„ä¼°æ•ˆæœï¼Œç”¨äºåç»­è®­ç»ƒ
            ScheduledExecutorService evaluator = Executors.newSingleThreadScheduledExecutor();
            evaluator.schedule(() -> {
                evaluateOptimizationEffect(snapshot);
            }, 60, TimeUnit.SECONDS);
        }

        private void evaluateOptimizationEffect(PerformanceSnapshot snapshot) {
            // è®¡ç®—ä¼˜åŒ–æ•ˆæœ
            double currentResponseTime = calculateCurrentResponseTime();
            double improvement = snapshot.getAverageResponseTime() - currentResponseTime;

            if (improvement > 10) { // æ”¹å–„è¶…è¿‡10ms
                // å°†æˆåŠŸçš„ä¼˜åŒ–æ·»åŠ åˆ°è®­ç»ƒæ•°æ®
                predictor.addTrainingData(snapshot.getFeatures(), snapshot.getThreadPoolSize());
                System.out.printf("ä¼˜åŒ–æ•ˆæœè‰¯å¥½ï¼Œæ·»åŠ åˆ°è®­ç»ƒæ•°æ®: æ”¹å–„ %.1f ms%n", improvement);
            } else {
                System.out.printf("ä¼˜åŒ–æ•ˆæœæœ‰é™: %.1f ms%n", improvement);
            }
        }

        private double calculateCurrentResponseTime() {
            return featureCollector.collectFeatures(inferencePool).getAverageResponseTime();
        }

        // æ€§èƒ½å†å²è®°å½•
        public static class PerformanceHistory {
            private final Queue<PerformanceSnapshot> snapshots = new ConcurrentLinkedQueue<>();

            public void addSnapshot(PerformanceSnapshot snapshot) {
                snapshots.offer(snapshot);
                while (snapshots.size() > 1000) {
                    snapshots.poll();
                }
            }

            public List<PerformanceSnapshot> getRecentSnapshots(int count) {
                return snapshots.stream()
                    .skip(Math.max(0, snapshots.size() - count))
                    .collect(Collectors.toList());
            }
        }

        // æ€§èƒ½å¿«ç…§
        public static class PerformanceSnapshot {
            private final FeatureVector features;
            private final int threadPoolSize;
            private final int activeThreads;
            private final int queueSize;
            private final long timestamp;

            public PerformanceSnapshot(FeatureVector features, int threadPoolSize,
                                     int activeThreads, int queueSize) {
                this.features = features;
                this.threadPoolSize = threadPoolSize;
                this.activeThreads = activeThreads;
                this.queueSize = queueSize;
                this.timestamp = System.currentTimeMillis();
            }

            // getters...
            public FeatureVector getFeatures() { return features; }
            public int getThreadPoolSize() { return threadPoolSize; }
            public int getActiveThreads() { return activeThreads; }
            public int getQueueSize() { return queueSize; }
            public double getAverageResponseTime() { return features.getAverageResponseTime(); }
            public long getTimestamp() { return timestamp; }
        }

        // æäº¤AIæ¨ç†ä»»åŠ¡
        public CompletableFuture<InferenceResult> submitInference(String modelId, Object input) {
            return CompletableFuture.supplyAsync(() -> {
                try {
                    Thread.sleep(20 + ThreadLocalRandom.current().nextInt(80));
                    return new InferenceResult("result_for_" + modelId, 0.95);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    return new InferenceResult("interrupted", 0.0);
                }
            }, inferencePool);
        }

        public void shutdown() {
            inferencePool.shutdown();
        }
    }

    // MLçº¿ç¨‹å·¥å‚
    public static class MLThreadFactory implements ThreadFactory {
        private final AtomicInteger threadNumber = new AtomicInteger(1);

        @Override
        public Thread newThread(Runnable r) {
            Thread t = new Thread(r, "AI-ML-" + threadNumber.getAndIncrement());
            t.setPriority(Thread.NORM_PRIORITY);
            t.setDaemon(false);
            return t;
        }
    }

    // MLæ‹’ç»å¤„ç†å™¨
    public static class MLRejectionHandler implements RejectedExecutionHandler {
        @Override
        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
            System.err.println("MLä¼˜åŒ–çš„çº¿ç¨‹æ± æ‹’ç»ä»»åŠ¡");
            throw new RejectedExecutionException("ä»»åŠ¡è¢«æ‹’ç»ï¼Œå½“å‰è´Ÿè½½è¿‡é«˜");
        }
    }

    public static void main(String[] args) {
        System.out.println("=== åŸºäºæœºå™¨å­¦ä¹ çš„çº¿ç¨‹æ± ä¼˜åŒ–ç³»ç»Ÿ ===");

        // åˆ›å»ºMLä¼˜åŒ–çš„çº¿ç¨‹æ± 
        MLThreadPoolOptimizer optimizer = new MLThreadPoolOptimizer(8);

        // æ¨¡æ‹ŸAIæ¨ç†è´Ÿè½½
        ExecutorService loadGenerator = Executors.newFixedThreadPool(10);
        Random random = new Random();

        for (int i = 0; i < 1000; i++) {
            final int taskId = i;
            loadGenerator.submit(() -> {
                String modelId = "model_" + (taskId % 10);
                Object input = "input_" + taskId;
                int priority = random.nextInt(10);

                CompletableFuture<InferenceResult> future = optimizer.submitInference(modelId, input);
                future.thenAccept(result -> {
                    // å¤„ç†æ¨ç†ç»“æœ
                });
            });

            // æ¨¡æ‹Ÿè´Ÿè½½å˜åŒ–
            try {
                Thread.sleep(100 + random.nextInt(200));
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                break;
            }
        }

        // è¿è¡Œä¸€æ®µæ—¶é—´åå…³é—­
        try {
            Thread.sleep(300000); // è¿è¡Œ5åˆ†é’Ÿ
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }

        loadGenerator.shutdown();
        optimizer.shutdown();
        System.out.println("MLçº¿ç¨‹æ± ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å®Œæˆ");
    }
}
```

## ğŸ’¡ é¢è¯•æŠ€å·§æç¤º

### çº¿ç¨‹æ± é¢è¯•è¦ç‚¹ï¼š

1. **åˆ†å±‚è®¾è®¡**: CPUå¯†é›†å‹vs IOå¯†é›†å‹ä»»åŠ¡çš„çº¿ç¨‹æ± åŒºåˆ†
2. **è‡ªé€‚åº”è°ƒä¼˜**: åŸºäºæŒ‡æ ‡åé¦ˆçš„åŠ¨æ€è°ƒæ•´ç­–ç•¥
3. **æ€§èƒ½ç›‘æ§**: å…³é”®æŒ‡æ ‡çš„æ”¶é›†å’Œåˆ†ææ–¹æ³•
4. **æ‹’ç»ç­–ç•¥**: å¦‚ä½•å¤„ç†ä»»åŠ¡è¢«æ‹’ç»çš„æƒ…å†µ
5. **MLä¼˜åŒ–**: æœºå™¨å­¦ä¹ åœ¨ç³»ç»Ÿè°ƒä¼˜ä¸­çš„åˆ›æ–°åº”ç”¨

### å¸¸è§é”™è¯¯ï¼š
- ä¸è€ƒè™‘ä»»åŠ¡ç‰¹æ€§ç›²ç›®è®¾ç½®çº¿ç¨‹æ± å¤§å°
- ç¼ºä¹åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼Œæ— æ³•åº”å¯¹è´Ÿè½½å˜åŒ–
- å¿½ç•¥æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†
- æ²¡æœ‰è€ƒè™‘çº¿ç¨‹æ± çš„å…³é—­å’Œèµ„æºæ¸…ç†
- ä¸äº†è§£ç°ä»£JVMçš„çº¿ç¨‹æ± ä¼˜åŒ–ç‰¹æ€§

é€šè¿‡è¿™äº›é¢˜ç›®ï¼Œé¢è¯•å®˜èƒ½å…¨é¢è€ƒå¯Ÿå€™é€‰äººå¯¹Javaå¹¶å‘ç¼–ç¨‹çš„æ·±åº¦ç†è§£å’ŒAIç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–èƒ½åŠ›ã€‚